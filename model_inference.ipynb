{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# imports and stuff",
   "id": "39758e32da2f7a9a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T14:44:06.208836Z",
     "start_time": "2025-04-10T14:44:04.027857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# Set up MLflow tracking with DagsHub\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/qetibakh/ML-Homework1.mlflow/\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"qetibakh\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"5d5729711347a10a69c47eea029df715cc67e1ce\"\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# We also need the training data for reference\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "\n",
    "# Load the best model from MLflow Model Registry\n",
    "model_name = \"house_price_xgboost\"\n",
    "model_version = \"2\"  # Use the latest version (version 2 based on your output)\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "print(f\"Loading model from {model_uri}\")\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Start preprocessing - reproduce the same steps from model_experiment.ipynb\n",
    "print(\"Starting data preprocessing...\")\n",
    "# Save original copies for reference\n",
    "train_original = train_data.copy()\n",
    "test_original = test_data.copy()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1459, 80)\n",
      "Training data shape: (1460, 81)\n",
      "Loading model from models:/house_price_xgboost/2\n",
      "Starting data preprocessing...\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## cleaning",
   "id": "a6ed741b65aeff88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:15.390765Z",
     "start_time": "2025-04-10T14:44:06.217533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start MLflow run for cleaning\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"data_cleaning\")\n",
    "\n",
    "# Function to log cleaning steps\n",
    "def log_cleaning_step(description, affected_columns, technique):\n",
    "    mlflow.log_param(f\"cleaning_step_{description}_columns\", str(affected_columns))\n",
    "    mlflow.log_param(f\"cleaning_step_{description}_technique\", technique)\n",
    "\n",
    "# Combine train and test for preprocessing\n",
    "all_data = pd.concat([train_data.drop('SalePrice', axis=1), test_data])\n",
    "print(f\"Combined data shape: {all_data.shape}\")\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "num_features = all_data.select_dtypes(include=[np.number]).columns\n",
    "cat_features = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Handle missing numerical data\n",
    "numerical_na_cols = all_data[num_features].isnull().sum()[all_data[num_features].isnull().sum() > 0].index.tolist()\n",
    "print(f\"Numerical features with missing values: {numerical_na_cols}\")\n",
    "\n",
    "for col in numerical_na_cols:\n",
    "    # Custom handling for each column with missing values\n",
    "    if \"garage\" in col.lower() or \"bsmt\" in col.lower():\n",
    "        # These are likely 0 if missing (no garage/basement)\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "        log_cleaning_step(f\"fill_na_{col}\", col, \"fill_with_zero_as_feature_absent\")\n",
    "    else:\n",
    "        # Fill with median for other numerical features\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "        log_cleaning_step(f\"fill_na_{col}\", col, \"fill_with_median\")\n",
    "\n",
    "# Handle missing categorical data\n",
    "categorical_na_cols = all_data[cat_features].isnull().sum()[all_data[cat_features].isnull().sum() > 0].index.tolist()\n",
    "print(f\"Categorical features with missing values: {categorical_na_cols}\")\n",
    "\n",
    "for col in categorical_na_cols:\n",
    "    if col in [\"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\"]:\n",
    "        # These are often NA because the feature doesn't exist\n",
    "        all_data[col].fillna(\"None\", inplace=True)\n",
    "        log_cleaning_step(f\"fill_na_{col}\", col, \"fill_with_None_as_feature_absent\")\n",
    "    elif \"garage\" in col.lower() or \"bsmt\" in col.lower():\n",
    "        # If these are missing, likely no garage/basement\n",
    "        all_data[col].fillna(\"None\", inplace=True)\n",
    "        log_cleaning_step(f\"fill_na_{col}\", col, \"fill_with_None_as_feature_absent\")\n",
    "    else:\n",
    "        # For other categorical features, use mode\n",
    "        all_data[col].fillna(all_data[col].mode()[0], inplace=True)\n",
    "        log_cleaning_step(f\"fill_na_{col}\", col, \"fill_with_mode\")\n",
    "\n",
    "# Check for remaining missing values\n",
    "missing_after = all_data.isnull().sum().sum()\n",
    "if missing_after > 0:\n",
    "    print(\"Columns with remaining missing values:\")\n",
    "    print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
    "\n",
    "    # Fill any remaining NaN values with appropriate values\n",
    "    # For numeric columns, use median\n",
    "    num_cols = all_data.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_cols:\n",
    "        if all_data[col].isnull().sum() > 0:\n",
    "            all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "            print(f\"Filled NaN values in numeric column {col} with median\")\n",
    "\n",
    "    # For categorical columns, use mode\n",
    "    cat_cols = all_data.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        if all_data[col].isnull().sum() > 0:\n",
    "            all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "            print(f\"Filled NaN values in categorical column {col} with mode\")\n",
    "\n",
    "# Final verification\n",
    "assert all_data.isnull().sum().sum() == 0, \"There are still missing values after cleaning!\"\n",
    "print(\"All missing values have been handled successfully.\")\n",
    "\n",
    "# End cleaning MLflow run\n",
    "mlflow.end_run()"
   ],
   "id": "5e77e5ce26113398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (2919, 80)\n",
      "Numerical features with missing values: ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']\n",
      "Categorical features with missing values: ['MSZoning', 'Alley', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qeto\\AppData\\Local\\Temp\\ipykernel_8716\\1601012655.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_data[col].fillna(all_data[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Qeto\\AppData\\Local\\Temp\\ipykernel_8716\\1601012655.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_data[col].fillna(\"None\", inplace=True)\n",
      "C:\\Users\\Qeto\\AppData\\Local\\Temp\\ipykernel_8716\\1601012655.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_data[col].fillna(\"None\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All missing values have been handled successfully.\n",
      "ðŸƒ View run data_cleaning at: https://dagshub.com/qetibakh/ML-Homework1.mlflow/#/experiments/0/runs/b3110ee21d2a45b8b5a88b06d87c681e\n",
      "ðŸ§ª View experiment at: https://dagshub.com/qetibakh/ML-Homework1.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## feature engineering",
   "id": "71027f162a07ae9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:39.346156Z",
     "start_time": "2025-04-10T14:45:15.473511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start MLflow run for feature engineering\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"feature_engineering\")\n",
    "\n",
    "# Function to log feature engineering steps\n",
    "def log_feature_eng_step(description, technique, affected_columns=None, created_columns=None):\n",
    "    if affected_columns:\n",
    "        mlflow.log_param(f\"fe_step_{description}_affected\", str(affected_columns))\n",
    "    if created_columns:\n",
    "        mlflow.log_param(f\"fe_step_{description}_created\", str(created_columns))\n",
    "    mlflow.log_param(f\"fe_step_{description}_technique\", technique)\n",
    "\n",
    "# Transform skewed numerical features\n",
    "numeric_features = all_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate skewness for each numerical feature\n",
    "from scipy import stats\n",
    "skewed_features = all_data[numeric_features].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\n",
    "high_skew_features = skewed_features[skewed_features > 0.5].index\n",
    "\n",
    "print(f\"Number of highly skewed features: {len(high_skew_features)}\")\n",
    "mlflow.log_param(\"num_skewed_features\", len(high_skew_features))\n",
    "\n",
    "# Apply log transformation to highly skewed features\n",
    "for feature in high_skew_features:\n",
    "    # Adding 1 to avoid log(0)\n",
    "    all_data[feature] = np.log1p(all_data[feature])\n",
    "\n",
    "log_feature_eng_step(\"log_transform_skewed\", \"log1p_transform\", affected_columns=high_skew_features.tolist())\n",
    "\n",
    "# Encode categorical variables\n",
    "# Ordinal encoding for quality and condition features\n",
    "ordinal_quality_mapping = {\n",
    "    'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0, 'NA': 0\n",
    "}\n",
    "\n",
    "quality_cols = [col for col in all_data.columns if 'Qual' in col or 'Cond' in col]\n",
    "quality_cols = [col for col in quality_cols if col in cat_features]\n",
    "\n",
    "for col in quality_cols:\n",
    "    all_data[col + '_Encoded'] = all_data[col].map(ordinal_quality_mapping)\n",
    "\n",
    "log_feature_eng_step(\"ordinal_encoding_quality\", \"ordinal_mapping\",\n",
    "                    affected_columns=quality_cols,\n",
    "                    created_columns=[col + '_Encoded' for col in quality_cols])\n",
    "\n",
    "# One-hot encoding for other categorical features\n",
    "categorical_cols = [col for col in cat_features if col not in quality_cols]\n",
    "print(f\"Number of categorical columns to one-hot encode: {len(categorical_cols)}\")\n",
    "\n",
    "# Apply one-hot encoding\n",
    "all_data_encoded = pd.get_dummies(all_data, columns=categorical_cols, drop_first=True)\n",
    "print(f\"Shape after one-hot encoding: {all_data_encoded.shape}\")\n",
    "\n",
    "log_feature_eng_step(\"one_hot_encoding\", \"pd_get_dummies\",\n",
    "                    affected_columns=categorical_cols,\n",
    "                    created_columns=[col for col in all_data_encoded.columns if col not in all_data.columns])\n",
    "\n",
    "# Create new features\n",
    "# Total square footage\n",
    "all_data_encoded['TotalSF'] = all_data_encoded['1stFlrSF'] + all_data_encoded['2ndFlrSF'] + all_data_encoded['TotalBsmtSF']\n",
    "log_feature_eng_step(\"total_square_feet\", \"sum_areas\",\n",
    "                    affected_columns=['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF'],\n",
    "                    created_columns=['TotalSF'])\n",
    "\n",
    "# Total bathrooms\n",
    "all_data_encoded['TotalBath'] = all_data_encoded['FullBath'] + 0.5 * all_data_encoded['HalfBath'] + \\\n",
    "                               all_data_encoded['BsmtFullBath'] + 0.5 * all_data_encoded['BsmtHalfBath']\n",
    "log_feature_eng_step(\"total_bathrooms\", \"weighted_sum\",\n",
    "                    affected_columns=['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath'],\n",
    "                    created_columns=['TotalBath'])\n",
    "\n",
    "# House age and when it was remodeled\n",
    "all_data_encoded['Age'] = all_data_encoded['YrSold'] - all_data_encoded['YearBuilt']\n",
    "all_data_encoded['Remodeled'] = (all_data_encoded['YearRemodAdd'] != all_data_encoded['YearBuilt']).astype(int)\n",
    "all_data_encoded['RemodAge'] = all_data_encoded['YrSold'] - all_data_encoded['YearRemodAdd']\n",
    "log_feature_eng_step(\"age_features\", \"year_differences\",\n",
    "                    affected_columns=['YrSold', 'YearBuilt', 'YearRemodAdd'],\n",
    "                    created_columns=['Age', 'Remodeled', 'RemodAge'])\n",
    "\n",
    "# Log features created\n",
    "mlflow.log_param(\"num_features_before\", all_data.shape[1])\n",
    "mlflow.log_param(\"num_features_after\", all_data_encoded.shape[1])\n",
    "mlflow.log_param(\"new_features_created\", all_data_encoded.shape[1] - all_data.shape[1])\n",
    "\n",
    "# End feature engineering MLflow run\n",
    "mlflow.end_run()"
   ],
   "id": "8c66d4ea8787f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of highly skewed features: 25\n",
      "Number of categorical columns to one-hot encode: 33\n",
      "Shape after one-hot encoding: (2919, 230)\n",
      "ðŸƒ View run feature_engineering at: https://dagshub.com/qetibakh/ML-Homework1.mlflow/#/experiments/0/runs/65955a5ecbea4c43adf5b03bfd1fe0f4\n",
      "ðŸ§ª View experiment at: https://dagshub.com/qetibakh/ML-Homework1.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## feature selection",
   "id": "c56d0ba77d4d7a44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:54.356701Z",
     "start_time": "2025-04-10T14:45:39.352468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start MLflow run for feature selection\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"feature_selection\")\n",
    "\n",
    "# Let's first check what's happening with the indices\n",
    "print(f\"Original train data shape: {train_original.shape}\")\n",
    "print(f\"Original train index range: {min(train_original.index)} to {max(train_original.index)}\")\n",
    "print(f\"all_data_encoded shape: {all_data_encoded.shape}\")\n",
    "print(f\"all_data_encoded index range: {min(all_data_encoded.index)} to {max(all_data_encoded.index)}\")\n",
    "\n",
    "# We need to understand the difference between train_original.index and train_idx\n",
    "train_idx = train_original.index\n",
    "\n",
    "# A better approach - use integer positions since we know train data comes first\n",
    "train_rows = train_original.shape[0]\n",
    "X_train_full = all_data_encoded.iloc[:train_rows].copy()\n",
    "X_test = all_data_encoded.iloc[train_rows:].copy()\n",
    "y_train = np.log1p(train_original['SalePrice'])  # Log transform for better model performance\n",
    "\n",
    "# Verify the shapes are correct\n",
    "print(f\"X_train_full shape: {X_train_full.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "assert X_train_full.shape[0] == y_train.shape[0], \"X and y have different number of samples!\"\n",
    "\n",
    "# Check for categorical columns that might cause issues\n",
    "categorical_columns = X_train_full.select_dtypes(include=['object']).columns\n",
    "if len(categorical_columns) > 0:\n",
    "    print(f\"Found categorical columns that need handling: {categorical_columns.tolist()}\")\n",
    "    # Create a numeric-only version of the data\n",
    "    X_train_full_numeric = X_train_full.select_dtypes(include=[np.number])\n",
    "    print(f\"Using {X_train_full_numeric.shape[1]} numeric features for all feature selection methods\")\n",
    "else:\n",
    "    X_train_full_numeric = X_train_full\n",
    "    print(\"All features are already numeric\")\n",
    "\n",
    "# Check for and handle NaN values\n",
    "if X_train_full_numeric.isnull().values.any():\n",
    "    print(f\"Found NaN values in numeric data.\")\n",
    "    # Count NaN values by column\n",
    "    nan_counts = X_train_full_numeric.isnull().sum()\n",
    "    columns_with_nan = nan_counts[nan_counts > 0]\n",
    "    print(f\"Columns with NaN values:\\n{columns_with_nan}\")\n",
    "\n",
    "    # Identify columns that are entirely NaN\n",
    "    all_nan_columns = [col for col in X_train_full_numeric.columns\n",
    "                      if X_train_full_numeric[col].isnull().all()]\n",
    "\n",
    "    if all_nan_columns:\n",
    "        print(f\"These columns are entirely NaN and will be dropped: {all_nan_columns}\")\n",
    "        X_train_full_numeric = X_train_full_numeric.drop(columns=all_nan_columns)\n",
    "\n",
    "    # For the remaining columns with some NaN values, fill with median\n",
    "    for col in X_train_full_numeric.columns:\n",
    "        if X_train_full_numeric[col].isnull().any():\n",
    "            X_train_full_numeric[col] = X_train_full_numeric[col].fillna(X_train_full_numeric[col].median())\n",
    "            print(f\"Filled NaN values in column {col} with median\")\n",
    "\n",
    "    # Verify no NaN values remain\n",
    "    assert not X_train_full_numeric.isnull().values.any(), \"NaN values still present after filling\"\n",
    "    print(\"All NaN values have been handled\")\n",
    "\n",
    "# Correlation with target variable\n",
    "correlation_method = {}\n",
    "\n",
    "# Add SalePrice back for correlation calculation\n",
    "X_train_with_target = X_train_full_numeric.copy()\n",
    "X_train_with_target['SalePrice'] = train_original['SalePrice']\n",
    "\n",
    "# Calculate correlation using only numeric data\n",
    "correlation = X_train_with_target.corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "# Select features with absolute correlation > threshold\n",
    "thresholds = [0.1, 0.2, 0.3]\n",
    "for threshold in thresholds:\n",
    "    corr_selected = correlation[abs(correlation) > threshold].index.tolist()\n",
    "    corr_selected.remove('SalePrice')  # Remove target\n",
    "    correlation_method[f\"corr_{threshold}\"] = corr_selected\n",
    "    print(f\"Selected {len(corr_selected)} features using correlation threshold {threshold}\")\n",
    "    mlflow.log_param(f\"num_features_corr_{threshold}\", len(corr_selected))\n",
    "\n",
    "# Lasso feature selection\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Use numeric-only data for Lasso\n",
    "lasso_selector = SelectFromModel(Lasso(alpha=0.005, random_state=42))\n",
    "lasso_selector.fit(X_train_full_numeric, y_train)\n",
    "\n",
    "lasso_selected = X_train_full_numeric.columns[lasso_selector.get_support()].tolist()\n",
    "print(f\"Selected {len(lasso_selected)} features using Lasso\")\n",
    "mlflow.log_param(\"num_features_lasso\", len(lasso_selected))\n",
    "\n",
    "# Random Forest feature importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Use numeric-only data for Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_full_numeric, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select top features by importance\n",
    "rf_selected_top30 = X_train_full_numeric.columns[indices[:min(30, len(indices))]].tolist()\n",
    "rf_selected_top50 = X_train_full_numeric.columns[indices[:min(50, len(indices))]].tolist()\n",
    "\n",
    "print(f\"Selected top 30 features using Random Forest importance\")\n",
    "print(f\"Selected top 50 features using Random Forest importance\")\n",
    "mlflow.log_param(\"num_features_rf_top30\", len(rf_selected_top30))\n",
    "mlflow.log_param(\"num_features_rf_top50\", len(rf_selected_top50))\n",
    "\n",
    "# Create different feature sets for experimentation\n",
    "feature_sets = {\n",
    "    'all_features_numeric': X_train_full_numeric.columns.tolist(),\n",
    "    'corr_0.1': correlation_method['corr_0.1'],\n",
    "    'corr_0.3': correlation_method['corr_0.3'],\n",
    "    'lasso_selected': lasso_selected,\n",
    "    'rf_top30': rf_selected_top30,\n",
    "    'rf_top50': rf_selected_top50\n",
    "}\n",
    "\n",
    "# Log feature sets\n",
    "for set_name, features in feature_sets.items():\n",
    "    mlflow.log_param(f\"feature_set_{set_name}_count\", len(features))\n",
    "\n",
    "# End feature selection MLflow run\n",
    "mlflow.end_run()"
   ],
   "id": "904918747e2d783f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data shape: (1460, 81)\n",
      "Original train index range: 0 to 1459\n",
      "all_data_encoded shape: (2919, 235)\n",
      "all_data_encoded index range: 0 to 1459\n",
      "X_train_full shape: (1460, 235)\n",
      "y_train shape: (1460,)\n",
      "X_test shape: (1459, 235)\n",
      "Found categorical columns that need handling: ['Condition1', 'Condition2', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'KitchenQual', 'GarageQual', 'GarageCond', 'SaleCondition']\n",
      "Using 52 numeric features for all feature selection methods\n",
      "Found NaN values in numeric data.\n",
      "Columns with NaN values:\n",
      "Condition1_Encoded       1460\n",
      "Condition2_Encoded       1460\n",
      "SaleCondition_Encoded    1460\n",
      "dtype: int64\n",
      "These columns are entirely NaN and will be dropped: ['Condition1_Encoded', 'Condition2_Encoded', 'SaleCondition_Encoded']\n",
      "All NaN values have been handled\n",
      "Selected 35 features using correlation threshold 0.1\n",
      "Selected 29 features using correlation threshold 0.2\n",
      "Selected 22 features using correlation threshold 0.3\n",
      "Selected 24 features using Lasso\n",
      "Selected top 30 features using Random Forest importance\n",
      "Selected top 50 features using Random Forest importance\n",
      "ðŸƒ View run feature_selection at: https://dagshub.com/qetibakh/ML-Homework1.mlflow/#/experiments/0/runs/afdd2a22e6244df48b06dbbb6df8decf\n",
      "ðŸ§ª View experiment at: https://dagshub.com/qetibakh/ML-Homework1.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## submission file",
   "id": "704767e72d732736"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:45:54.523894Z",
     "start_time": "2025-04-10T14:45:54.493818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Making predictions...\")\n",
    "# Extract test data from the processed dataset\n",
    "test_data_processed = X_test.copy()\n",
    "\n",
    "# Check for NaN values in preprocessed test data\n",
    "if test_data_processed.isnull().values.any():\n",
    "    print(\"Warning: NaN values found in preprocessed test data\")\n",
    "    print(test_data_processed.isnull().sum()[test_data_processed.isnull().sum() > 0])\n",
    "    # Fill NaN values with 0\n",
    "    test_data_processed = test_data_processed.fillna(0)\n",
    "    print(\"Filled NaN values with 0\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_data_processed)\n",
    "\n",
    "# Transform back from log space\n",
    "predictions = np.expm1(predictions)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'],\n",
    "    'SalePrice': predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")\n",
    "\n",
    "# Display first 5 predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(submission.head())"
   ],
   "id": "24801fa529b78fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 18:45:54 WARNING mlflow.models.utils: Found extra inputs in the model input that are not defined in the model signature: `['MiscFeature_TenC', 'Exterior2nd_Wd Shng', 'LotShape_IR2', 'Fence_GdWo', 'HouseStyle_2.5Unf', 'GarageFinish_None', 'Exterior2nd_BrkFace', 'BsmtFinType1_None', 'LandContour_HLS', 'BsmtFinType1_Rec', 'BldgType_Twnhs', 'Electrical_Mix', 'Exterior2nd_Wd Sdng', 'Heating_Grav', 'PavedDrive_P', 'MSZoning_RH', 'Foundation_Stone', 'BsmtExposure_Gd', 'BsmtFinType2_None', 'GarageCond', 'LandSlope_Mod', 'Electrical_FuseP', 'RoofStyle_Gambrel', 'GarageType_BuiltIn', 'HeatingQC_Po', 'Neighborhood_Sawyer', 'Exterior2nd_MetalSd', 'GarageFinish_Unf', 'BsmtFinType2_Unf', 'Neighborhood_NAmes', 'GarageType_Detchd', 'MSZoning_FV', 'BsmtExposure_Mn', 'BsmtFinType2_GLQ', 'LandContour_Lvl', 'Exterior2nd_ImStucc', 'SaleType_CWD', 'BldgType_2fmCon', 'MiscFeature_Shed', 'BsmtFinType1_BLQ', 'Exterior1st_Stucco', 'Functional_Sev', 'MiscFeature_Othr', 'Exterior1st_BrkComm', 'Heating_OthW', 'Functional_Typ', 'FireplaceQu_Po', 'BsmtFinType2_LwQ', 'Foundation_Slab', 'Neighborhood_Somerst', 'Foundation_PConc', 'MasVnrType_BrkFace', 'BsmtFinType1_LwQ', 'Exterior2nd_Brk Cmn', 'KitchenQual', 'Exterior2nd_Other', 'GarageType_None', 'Neighborhood_SWISU', 'Exterior1st_VinylSd', 'Exterior2nd_CmentBd', 'PavedDrive_Y', 'Neighborhood_BrkSide', 'FireplaceQu_Fa', 'HeatingQC_Gd', 'Neighborhood_SawyerW', 'Neighborhood_ClearCr', 'Exterior1st_CBlock', 'HouseStyle_SLvl', 'Foundation_CBlock', 'RoofMatl_WdShake', 'Functional_Min1', 'SaleType_Con', 'Neighborhood_NWAmes', 'Alley_None', 'Exterior2nd_HdBoard', 'PoolQC_Fa', 'BldgType_Duplex', 'Neighborhood_CollgCr', 'HeatingQC_TA', 'MSZoning_RM', 'RoofMatl_CompShg', 'BsmtCond', 'Neighborhood_Mitchel', 'Heating_GasA', 'ExterQual', 'Exterior2nd_CBlock', 'SaleType_New', 'Fence_MnPrv', 'LotConfig_Inside', 'RoofMatl_Metal', 'HouseStyle_1Story', 'Utilities_NoSeWa', 'Exterior2nd_Plywood', 'SaleType_Oth', 'Exterior1st_AsphShn', 'Exterior1st_Stone', 'HouseStyle_2Story', 'Neighborhood_NPkVill', 'Neighborhood_Timber', 'Exterior1st_WdShing', 'SaleType_WD', 'Heating_Wall', 'Exterior1st_BrkFace', 'Foundation_Wood', 'Neighborhood_Veenker', 'Exterior2nd_Stone', 'Exterior1st_CemntBd', 'SaleType_ConLD', 'LotConfig_FR3', 'Neighborhood_BrDale', 'ExterCond', 'Heating_GasW', 'Neighborhood_IDOTRR', 'Functional_Maj2', 'Neighborhood_Blueste', 'RoofStyle_Hip', 'BsmtFinType1_GLQ', 'HouseStyle_2.5Fin', 'GarageQual', 'RoofStyle_Shed', 'RoofMatl_WdShngl', 'Exterior1st_Plywood', 'RoofMatl_Membran', 'LandSlope_Sev', 'LotShape_Reg', 'Exterior1st_HdBoard', 'MiscFeature_None', 'BsmtFinType2_Rec', 'RoofStyle_Gable', 'Neighborhood_Crawfor', 'BsmtExposure_None', 'GarageType_CarPort', 'PoolQC_Gd', 'HouseStyle_SFoyer', 'BsmtFinType1_Unf', 'Exterior1st_ImStucc', 'PoolQC_None', 'MasVnrType_Stone', 'LotConfig_CulDSac', 'GarageFinish_RFn', 'RoofMatl_Roll', 'Neighborhood_NoRidge', 'SaleType_ConLw', 'Condition1_Encoded', 'GarageType_Basment', 'SaleType_ConLI', 'GarageType_Attchd', 'Fence_None', 'Neighborhood_OldTown', 'Neighborhood_MeadowV', 'Neighborhood_NridgHt', 'Exterior1st_MetalSd', 'Exterior1st_Wd Sdng', 'Neighborhood_Edwards', 'Condition2', 'MSZoning_RL', 'Neighborhood_Gilbert', 'HeatingQC_Fa', 'Neighborhood_StoneBr', 'CentralAir_Y', 'BsmtExposure_No', 'RoofMatl_Tar&Grv', 'HouseStyle_1.5Unf', 'BsmtQual', 'Alley_Pave', 'BldgType_TwnhsE', 'Fence_MnWw', 'RoofStyle_Mansard', 'FireplaceQu_Gd', 'LotConfig_FR2', 'Street_Pave', 'Exterior2nd_VinylSd', 'Electrical_FuseF', 'SaleCondition_Encoded', 'SaleCondition', 'BsmtFinType2_BLQ', 'Functional_Min2', 'Condition1', 'Electrical_SBrkr', 'Exterior2nd_AsphShn', 'LotShape_IR3', 'LandContour_Low', 'Exterior2nd_Stucco', 'Functional_Mod', 'Condition2_Encoded', 'FireplaceQu_TA']`. These inputs will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Warning: NaN values found in preprocessed test data\n",
      "Condition1_Encoded       1459\n",
      "Condition2_Encoded       1459\n",
      "SaleCondition_Encoded    1459\n",
      "dtype: int64\n",
      "Filled NaN values with 0\n",
      "Submission file created successfully!\n",
      "\n",
      "Sample predictions:\n",
      "     Id      SalePrice\n",
      "0  1461  131459.640625\n",
      "1  1462  155973.375000\n",
      "2  1463  187002.140625\n",
      "3  1464  189090.859375\n",
      "4  1465  186770.625000\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
